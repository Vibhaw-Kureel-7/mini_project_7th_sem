{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YJH4j0p_ISOS",
        "outputId": "2970eb95-cb4e-45ae-fa78-345185ba9a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m462.8/462.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m351.3/351.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Cell 1: install packages (matching your notebook)\n",
        "# Note: these installs can be slow. Run once per new Colab session.\n",
        "\n",
        "# Core Unsloth stack (match your notebook)\n",
        "!pip install --quiet --no-deps bitsandbytes accelerate xformers==0.0.29.post3 \\\n",
        "    peft trl triton cut_cross_entropy unsloth_zoo\n",
        "\n",
        "!pip install --quiet sentencepiece protobuf \"datasets>=3.4.1\" \\\n",
        "    \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "\n",
        "# Unsloth (no-deps like in your Notebook)\n",
        "!pip install --quiet --no-deps unsloth\n",
        "\n",
        "# Pin TRL to the training-compatible version (your notebook pinned 0.22.2)\n",
        "!pip install --quiet --no-deps trl==0.22.2\n",
        "\n",
        "# Streamlit + ngrok + helper libs\n",
        "!pip install --quiet streamlit pyngrok gdown joblib==1.5.2 scikit-learn==1.7.2 xgboost==3.1.1 catboost==1.2.8\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Download TFIDF + Voting model ZIP + LoRA Adapters\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "WORKDIR = Path(\"/content/unsloth_streamlit\")\n",
        "WORKDIR.mkdir(parents=True, exist_ok=True)\n",
        "os.chdir(WORKDIR)\n",
        "\n",
        "# ------------------ File IDs ------------------\n",
        "ROUTER_ZIP_FILE_ID = \"1yTJg9RIDXuWyEFRYCliZTO52NhuTGZgS\"   # ‚úÖ contains tfidf & voting models\n",
        "LORA_ZIP_FILE_ID   = \"1Qc8eUaOrTY-Bw9M70PcKUpTedbbeZcaz\"   # ‚úÖ LoRA adapters\n",
        "# ------------------------------------------------\n",
        "\n",
        "print(\"üìÅ Working dir:\", WORKDIR)\n",
        "\n",
        "# ‚úÖ Download router zip\n",
        "router_zip = \"router_files.zip\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={ROUTER_ZIP_FILE_ID}\", router_zip, quiet=False)\n",
        "\n",
        "# ‚úÖ Unzip router files\n",
        "print(\"üì¶ Extracting router model files...\")\n",
        "with zipfile.ZipFile(router_zip, \"r\") as zf:\n",
        "    zf.extractall(WORKDIR)\n",
        "\n",
        "# ‚úÖ Verify files\n",
        "print(\"‚úÖ Router files extracted:\")\n",
        "for f in [\"tfidf_vectorizer.joblib\", \"voting_model.joblib\"]:\n",
        "    if Path(f).exists():\n",
        "        print(f\"   - {f}\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå {f} NOT FOUND ‚Äî upload manually!\")\n",
        "\n",
        "# ‚úÖ Download LoRA adapters zip\n",
        "lora_zip = \"lora_adapters.zip\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={LORA_ZIP_FILE_ID}\", lora_zip, quiet=False)\n",
        "\n",
        "# ‚úÖ Extract LoRA adapters\n",
        "print(\"\\nüì¶ Extracting LoRA adapters...\")\n",
        "with zipfile.ZipFile(lora_zip, \"r\") as zf:\n",
        "    zf.extractall(WORKDIR)\n",
        "\n",
        "# ‚úÖ List LoRA folders\n",
        "print(\"‚úÖ LoRA adapters found:\")\n",
        "for p in sorted(WORKDIR.iterdir()):\n",
        "    if p.is_dir() and (p.name[0].isdigit() or \"lora\" in p.name.lower()):\n",
        "        print(\"   -\", p.name)\n",
        "\n",
        "print(\"\\nüéØ All files ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xQ34xws8JZJl",
        "outputId": "c428b179-d44c-4a1e-d98b-7d112cebef14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Working dir: /content/unsloth_streamlit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yTJg9RIDXuWyEFRYCliZTO52NhuTGZgS\n",
            "To: /content/unsloth_streamlit/router_files.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.45M/1.45M [00:00<00:00, 110MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Extracting router model files...\n",
            "‚úÖ Router files extracted:\n",
            "   - tfidf_vectorizer.joblib\n",
            "   - voting_model.joblib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Qc8eUaOrTY-Bw9M70PcKUpTedbbeZcaz\n",
            "From (redirected): https://drive.google.com/uc?id=1Qc8eUaOrTY-Bw9M70PcKUpTedbbeZcaz&confirm=t&uuid=b060b480-8948-4f42-b654-a787c742c5be\n",
            "To: /content/unsloth_streamlit/lora_adapters.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751M/751M [00:15<00:00, 48.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì¶ Extracting LoRA adapters...\n",
            "‚úÖ LoRA adapters found:\n",
            "   - 10_AweMatrix\n",
            "   - 11_CosmosView\n",
            "   - 12_DevotionAl\n",
            "   - 13_FieldScanner\n",
            "   - 14_GunaClassifier\n",
            "   - 15_NexusCut\n",
            "   - 16_VirtueCompass\n",
            "   - 17_LifestyleOps\n",
            "   - 18_MokshaPath\n",
            "   - 1_CrisisCore\n",
            "   - 2_AtmaAnalytics\n",
            "   - 3_ActionFlow\n",
            "   - 4_Karmicknowledge\n",
            "   - 5_ZenithOS\n",
            "   - 6_Mindful_Modulator\n",
            "   - 7_SourceCode\n",
            "   - 8_Continuum\n",
            "   - 9_OmniPresence\n",
            "\n",
            "üéØ All files ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: detect adapter folders + produce friendly index -> folder -> title map\n",
        "import re\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "WORKDIR = Path(\"/content/unsloth_streamlit\")\n",
        "WORKDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) scan for candidate adapter folders (same approach as before)\n",
        "candidates = sorted([p for p in WORKDIR.iterdir() if p.is_dir()])\n",
        "\n",
        "adapter_map = {}   # index -> folder Path\n",
        "unmatched = []\n",
        "\n",
        "for p in candidates:\n",
        "    name = p.name\n",
        "    # pattern 1: lora_adapters_ch{n}\n",
        "    m = re.search(r\"lora_adapters_ch(\\d+)\", name, re.IGNORECASE)\n",
        "    if m:\n",
        "        idx = int(m.group(1))\n",
        "        adapter_map[idx] = p\n",
        "        continue\n",
        "    # pattern 2: leading number \"1_Name\" or \"1-Name\" or \"1 Name\"\n",
        "    m2 = re.match(r\"^(\\d+)[_\\-\\s].+\", name)\n",
        "    if m2:\n",
        "        idx = int(m2.group(1))\n",
        "        adapter_map[idx] = p\n",
        "        continue\n",
        "    # pattern 3: folder contains \"ch{n}\"\n",
        "    m3 = re.search(r\"ch(\\d+)\", name, re.IGNORECASE)\n",
        "    if m3:\n",
        "        adapter_map[int(m3.group(1))] = p\n",
        "        continue\n",
        "    # didn't match any pattern - keep for manual check\n",
        "    unmatched.append(p)\n",
        "\n",
        "# 2) friendly titles for chapters (from your llms/plan). Use these in the UI.\n",
        "CHAPTER_TITLES = {\n",
        "    1: \"CrisisCore ‚Äî Conflict & Compassion (Chapter 1)\",\n",
        "    2: \"AtmaAnalytics ‚Äî Self & Immortality (Chapter 2)\",\n",
        "    3: \"ActionFlow ‚Äî Karma Yoga (Chapter 3)\",\n",
        "    4: \"Karmicknowledge ‚Äî Knowledge + Action (Chapter 4)\",\n",
        "    5: \"ZenithOS ‚Äî Renunciation in Action (Chapter 5)\",\n",
        "    6: \"Mindful Modulator ‚Äî Dhyana Yoga (Chapter 6)\",\n",
        "    7: \"SourceCode ‚Äî Metaphysics & Maya (Chapter 7)\",\n",
        "    8: \"Continuum ‚Äî Transition & Afterlife (Chapter 8)\",\n",
        "    9: \"OmniPresence ‚Äî Immanence & Devotion (Chapter 9)\",\n",
        "    10: \"AweMatrix ‚Äî Vibhutis & Inspiration (Chapter 10)\",\n",
        "    11: \"CosmosView ‚Äî Universal Form (Chapter 11)\",\n",
        "    12: \"DevotionAI ‚Äî Bhakti Yoga (Chapter 12)\",\n",
        "    13: \"FieldScanner ‚Äî Kshetra & Kshetragna (Chapter 13)\",\n",
        "    14: \"GunaClassifier ‚Äî Sattva/Rajas/Tamas (Chapter 14)\",\n",
        "    15: \"NexusCut ‚Äî Strategy of Detachment (Chapter 15)\",\n",
        "    16: \"VirtueCompass ‚Äî Divine & Demonic Qualities (Chapter 16)\",\n",
        "    17: \"LifestyleOps ‚Äî Practical Guna Guidance (Chapter 17)\",\n",
        "    18: \"MokshaPath ‚Äî Renunciation & Liberation (Chapter 18)\",\n",
        "}\n",
        "\n",
        "# 3) assemble final index map for JSON output\n",
        "final_map = {}\n",
        "for idx in sorted(CHAPTER_TITLES.keys()):\n",
        "    folder = adapter_map.get(idx)\n",
        "    final_map[idx] = {\n",
        "        \"index\": idx,\n",
        "        \"title\": CHAPTER_TITLES[idx],\n",
        "        \"folder_name\": folder.name if folder is not None else None,\n",
        "        \"folder_path\": str(folder.resolve()) if folder is not None else None,\n",
        "        \"present\": bool(folder is not None)\n",
        "    }\n",
        "\n",
        "# 4) save to disk so the Streamlit app can load friendly names\n",
        "out_json = WORKDIR / \"adapter_index_map.json\"\n",
        "with out_json.open(\"w\", encoding=\"utf-8\") as fh:\n",
        "    json.dump(final_map, fh, indent=2, ensure_ascii=False)\n",
        "\n",
        "# 5) print a neat summary for you to inspect\n",
        "print(f\"Working dir: {WORKDIR}\")\n",
        "present = [k for k,v in final_map.items() if v[\"present\"]]\n",
        "missing = [k for k,v in final_map.items() if not v[\"present\"]]\n",
        "print(f\"Detected {len(present)} adapters out of 18 expected.\")\n",
        "print(\"Summary (Index : Title -> folder_name):\")\n",
        "for k in sorted(final_map.keys()):\n",
        "    v = final_map[k]\n",
        "    status = \"OK\" if v[\"present\"] else \"MISSING\"\n",
        "    print(f\" {k:02d}: {v['title']}\\n      -> {v['folder_name'] or '<not found>'}  [{status}]\")\n",
        "\n",
        "if unmatched:\n",
        "    print(\"\\nFolders that didn't match index patterns (please inspect manually):\")\n",
        "    for p in unmatched:\n",
        "        print(\" -\", p.name)\n",
        "\n",
        "print(f\"\\nAdapter index map written to: {out_json}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1JKyoCX653g5",
        "outputId": "638f2225-dab9-492f-e1c9-824ea27f6d46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working dir: /content/unsloth_streamlit\n",
            "Detected 18 adapters out of 18 expected.\n",
            "Summary (Index : Title -> folder_name):\n",
            " 01: CrisisCore ‚Äî Conflict & Compassion (Chapter 1)\n",
            "      -> 1_CrisisCore  [OK]\n",
            " 02: AtmaAnalytics ‚Äî Self & Immortality (Chapter 2)\n",
            "      -> 2_AtmaAnalytics  [OK]\n",
            " 03: ActionFlow ‚Äî Karma Yoga (Chapter 3)\n",
            "      -> 3_ActionFlow  [OK]\n",
            " 04: Karmicknowledge ‚Äî Knowledge + Action (Chapter 4)\n",
            "      -> 4_Karmicknowledge  [OK]\n",
            " 05: ZenithOS ‚Äî Renunciation in Action (Chapter 5)\n",
            "      -> 5_ZenithOS  [OK]\n",
            " 06: Mindful Modulator ‚Äî Dhyana Yoga (Chapter 6)\n",
            "      -> 6_Mindful_Modulator  [OK]\n",
            " 07: SourceCode ‚Äî Metaphysics & Maya (Chapter 7)\n",
            "      -> 7_SourceCode  [OK]\n",
            " 08: Continuum ‚Äî Transition & Afterlife (Chapter 8)\n",
            "      -> 8_Continuum  [OK]\n",
            " 09: OmniPresence ‚Äî Immanence & Devotion (Chapter 9)\n",
            "      -> 9_OmniPresence  [OK]\n",
            " 10: AweMatrix ‚Äî Vibhutis & Inspiration (Chapter 10)\n",
            "      -> 10_AweMatrix  [OK]\n",
            " 11: CosmosView ‚Äî Universal Form (Chapter 11)\n",
            "      -> 11_CosmosView  [OK]\n",
            " 12: DevotionAI ‚Äî Bhakti Yoga (Chapter 12)\n",
            "      -> 12_DevotionAl  [OK]\n",
            " 13: FieldScanner ‚Äî Kshetra & Kshetragna (Chapter 13)\n",
            "      -> 13_FieldScanner  [OK]\n",
            " 14: GunaClassifier ‚Äî Sattva/Rajas/Tamas (Chapter 14)\n",
            "      -> 14_GunaClassifier  [OK]\n",
            " 15: NexusCut ‚Äî Strategy of Detachment (Chapter 15)\n",
            "      -> 15_NexusCut  [OK]\n",
            " 16: VirtueCompass ‚Äî Divine & Demonic Qualities (Chapter 16)\n",
            "      -> 16_VirtueCompass  [OK]\n",
            " 17: LifestyleOps ‚Äî Practical Guna Guidance (Chapter 17)\n",
            "      -> 17_LifestyleOps  [OK]\n",
            " 18: MokshaPath ‚Äî Renunciation & Liberation (Chapter 18)\n",
            "      -> 18_MokshaPath  [OK]\n",
            "\n",
            "Adapter index map written to: /content/unsloth_streamlit/adapter_index_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FINAL Cell-4 (Customized with Advancements.pdf frontend)\n",
        "from pathlib import Path\n",
        "\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import joblib, re, os, json, torch, time\n",
        "from pathlib import Path\n",
        "from unsloth import FastLanguageModel\n",
        "from peft import PeftModel\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# ----- CONFIG -----\n",
        "# (Using paths and models from your original base file)\n",
        "BASE_MODEL = \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\"\n",
        "TFIDF_PATH = \"/content/unsloth_streamlit/tfidf_vectorizer.joblib\"\n",
        "VOTING_PATH = \"/content/unsloth_streamlit/voting_model.joblib\"\n",
        "WORKDIR = Path(\"/content/unsloth_streamlit\")\n",
        "MODEL_MAP_FILE = WORKDIR / \"adapter_index_map.json\"\n",
        "MAX_NEW_TOKENS = 256\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# -------------------\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Council of 18 AI Wisdom Council\",\n",
        "    page_icon=\"üïâÔ∏è\",\n",
        "    layout=\"wide\" # Changed from 'centered'\n",
        ")\n",
        "\n",
        "# ----- LLM PROFILES (from Advancements.pdf) -----\n",
        "LLM_LONG = {\n",
        "    1: \"CrisisCore - First-contact counselor for heavy emotions, moral fog, grief, and urgent dilemmas. Blends grounding breath work.\",\n",
        "    2: \"AtmaAnalytics - Teacher of the immortal self. Reframes pressure and fear by distinguishing the perishable body-mind stream.\",\n",
        "    3: \"ActionFlow - Karma-Yoga tactician. Turns paralysis into momentum; maps tasks into duty, priority, and tiny next steps while.\",\n",
        "    4: \"Karmicknowledge - Integrates knowledge (Jnana) with action (Karma). Shows how insight informs behavior and how behavior matures.\",\n",
        "    5: \"ZenithOS - Renunciation engineer. Distinguishes renouncing the fruits vs renouncing action itself. Guides fully engaged effort.\",\n",
        "    6: \"Mindful Modulator - Meditation coach. Offers simple, reproducible attention drills, breath pacing, and mental labeling to.\",\n",
        "    7: \"SourceCode - Metaphysics & Maya. Explains matter, mind, ego, and the organizing intelligence behind appearances. Focus: big.\",\n",
        "    8: \"Continuum - Death & transition specialist. Addresses loss, endings, and change; gives language for grief while placing even.\",\n",
        "    9: \"OmniPresence - Devotion in daily life. Teaches offering actions and outcomes, turning routine into practice. Focus: presence.\",\n",
        "    10: \"AweMatrix - Vibhuti (excellences) explorer. Points at patterns of excellence in nature, science, arts, and people to rekindle.\",\n",
        "    11: \"CosmosView - Universal Form integrator. Holds overwhelm, zooms out to the cosmic canvas, then zooms back into one courageous.\",\n",
        "    12: \"DevotionAI - Path of love. Models qualities of a devoted heart‚Äîhumility, fearlessness, compassion‚Äîand translates them into.\",\n",
        "    13: \"FieldScanner - Kshetra/Kshetrajna analyzer. Separates signals of the body-mind field from the knower (witness). Focus: meta.\",\n",
        "    14: \"GunaClassifier - Reads Sattva/Rajas/Tamas patterns in food, sleep, work, speech. Suggests micro-shifts to tilt toward clarity.\",\n",
        "    15: \"NexusCut - Detachment strategist. Maps entanglements (people, habits, narratives) and offers the 'axe'‚Äîclear, compassionate.\",\n",
        "    16: \"VirtueCompass - Ethics navigator. Contrasts constructive (daivi) vs destructive (asuri) qualities and proposes experiments.\",\n",
        "    17: \"LifestyleOps - Classifies faith, food, charity, and austerity by Gunas; prescribes sustainable tweaks. Focus: lifestyle oper.\",\n",
        "    18: \"MokshaPath - Synthesis & surrender. Unifies all paths; shows how humble surrender accelerates growth when effort has plateaud.\"\n",
        "}\n",
        "\n",
        "# ----- NEW CSS (from Advancements.pdf) -----\n",
        "st.markdown('''\n",
        "<style>\n",
        ":root {\n",
        "    --card-bg: #ffffff;\n",
        "    --muted: #666;\n",
        "    --border: rgba(0,0,0,0.08);\n",
        "    --resp-bg: #fafbff;\n",
        "    --resp-fg: #111;\n",
        "    --loader-bg: linear-gradient(180deg, #fff, #f5f7ff);\n",
        "    --loader-fg: #111;\n",
        "}\n",
        "@media (prefers-color-scheme: dark) {\n",
        "    :root {\n",
        "        --card-bg: #10131a;\n",
        "        --muted: #b4b8c2;\n",
        "        --border: rgba(255,255,255,0.09);\n",
        "        --resp-bg: #0f172a;\n",
        "        --resp-fg: #e5e7eb;\n",
        "        --loader-bg: linear-gradient(180deg, #0f172a, #111827);\n",
        "        --loader-fg: #e5e7eb;\n",
        "    }\n",
        "}\n",
        "html, body, [data-testid=\"stAppViewContainer\"] {\n",
        "    font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, \"Helvetica Neue\", Arial, \"Noto Sans\", sans-serif;\n",
        "}\n",
        ".header-wrap { padding: 8px 0 4px 0; }\n",
        ".h1 { font-size: 28px; font-weight: 800; letter-spacing: -0.02em; }\n",
        ".subtle { color: var(--muted); font-size: 14px; margin-top: 2px; }\n",
        ".divider { height: 1px; background: var(--border); margin: 10px 0 14px 0; }\n",
        "\n",
        ".textarea .stTextArea textarea {\n",
        "    min-height: 170px !important; font-size: 15px;\n",
        "}\n",
        ".response {\n",
        "    border: 1px solid var(--border);\n",
        "    background: var(--resp-bg);\n",
        "    color: var(--resp-fg);\n",
        "    border-radius: 14px; padding: 16px 16px;\n",
        "    font-size: 16px; line-height: 1.55;\n",
        "    animation: fadeIn 400ms ease-in-out;\n",
        "    box-shadow: 0 1px 3px rgba(0,0,0,0.04);\n",
        "}\n",
        ".response pre, .response code { white-space: pre-wrap; }\n",
        ".btn-row button[kind=\"primary\"] { transition: transform 120ms ease; }\n",
        ".btn-row button[kind=\"primary\"]:active { transform: scale(0.98); }\n",
        "\n",
        ".sidebar-title { font-weight: 700; margin-bottom: 6px; font-size: 14px; }\n",
        ".member {\n",
        "    padding: 6px 8px; border-radius: 10px;\n",
        "    transition: background 150ms ease, transform 150ms ease;\n",
        "}\n",
        ".member:hover { background: rgba(75,123,236,0.12); transform: translateX(2px); }\n",
        ".member small { color: var(--muted); }\n",
        "\n",
        ".card {\n",
        "    background: var(--card-bg);\n",
        "    border: 1px solid var(--border);\n",
        "    border-left: 4px solid rgba(75,123,236,0.20);\n",
        "    border-radius: 12px; padding: 12px; margin-bottom: 10px;\n",
        "    height: 100%;\n",
        "}\n",
        ".fade-in { animation: fadeIn 450ms ease forwards; opacity: 0; }\n",
        "@keyframes fadeIn { from {opacity:0; transform: translateY(4px);} to {opacity:1; transform:none;}}\n",
        "\n",
        "/* Custom Loader box (theme-safe) */\n",
        ".loader-wrap {\n",
        "    border: 1px dashed var(--border);\n",
        "    border-radius: 14px; padding: 14px;\n",
        "    background: var(--loader-bg); color: var(--loader-fg);\n",
        "}\n",
        ".loader-line { font-size: 15px; margin-top: 6px; }\n",
        ".loader-dots::after {\n",
        "    content: ''; display: inline-block; width: 1.2em; text-align: left;\n",
        "    animation: dots 1.2s steps(4, end) infinite;\n",
        "}\n",
        "@keyframes dots { 0%, 20% {content: '';} 40% {content:'.';} 60% {content:'..';} 80%, 100% {content:'...';} }\n",
        "</style>\n",
        "''', unsafe_allow_html=True)\n",
        "\n",
        "# ----- NEW Header Function -----\n",
        "def header():\n",
        "    st.markdown(\n",
        "        '<div class=\"header-wrap\"><div class=\"h1\">Council of 18 ‚Äî AI Wisdom Council</div>'\n",
        "        '<div class=\"subtle\">18 specialised LLMs, routed by a classical ML ensemble.</div></div>',\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "    st.markdown( '<div class=\"divider\"></div>', unsafe_allow_html=True)\n",
        "\n",
        "# ----- Router (Unchanged) -----\n",
        "@st.cache_resource\n",
        "def load_router():\n",
        "    tfidf = joblib.load(TFIDF_PATH)\n",
        "    voting = joblib.load(VOTING_PATH)\n",
        "    return Pipeline([(\"tfidf\", tfidf), (\"ensemble\", voting)])\n",
        "router = load_router()\n",
        "\n",
        "# ----- Base Model (Unchanged) -----\n",
        "@st.cache_resource\n",
        "def load_base():\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=BASE_MODEL, max_seq_length=2048, load_in_4bit=True\n",
        "    )\n",
        "    return model, tokenizer\n",
        "base_model, tokenizer = load_base()\n",
        "\n",
        "# ----- Prompts (Unchanged) -----\n",
        "SYSTEM_PROMPTS = {\n",
        "1: \"Empathy & clarity for inner conflict.\",\n",
        "2: \"Soul is immortal. Stay steady.\",\n",
        "3: \"Selfless action without attachment.\",\n",
        "4: \"Knowledge + action harmony.\",\n",
        "5: \"Act fully, stay unattached.\",\n",
        "6: \"Meditation guidance.\",\n",
        "7: \"Divine metaphysics & Maya.\",\n",
        "8: \"Soul journey beyond body.\",\n",
        "9: \"Devotion and divine presence.\",\n",
        "10: \"Seeing divinity in excellence.\",\n",
        "11: \"Universal cosmic vision.\",\n",
        "12: \"Love & devotion path.\",\n",
        "13: \"Body vs soul discernment.\",\n",
        "14: \"Gunas analysis.\",\n",
        "15: \"Detach & rise to Supreme.\",\n",
        "16: \"Virtuous vs harmful traits.\",\n",
        "17: \"Lifestyle by Gunas.\",\n",
        "18: \"Liberation through surrender.\"\n",
        "}\n",
        "\n",
        "# ----- Load chapter map (Unchanged) -----\n",
        "adapter_index_map = {}\n",
        "if MODEL_MAP_FILE.exists():\n",
        "    adapter_index_map = json.loads(MODEL_MAP_FILE.read_text())\n",
        "\n",
        "if \"adapter_cache\" not in st.session_state:\n",
        "    st.session_state.adapter_cache = {}\n",
        "\n",
        "# ----- Utility Functions (Unchanged) -----\n",
        "def clean_text(x): return re.sub(r\"[^\\\\w\\\\s]\", \"\", x.lower())\n",
        "\n",
        "def find_adapter(idx):\n",
        "    idx = str(idx)\n",
        "    for p in WORKDIR.iterdir():\n",
        "        if p.is_dir() and p.name.startswith(idx + \"_\"):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def load_adapter(idx, folder):\n",
        "    if idx in st.session_state.adapter_cache:\n",
        "        return st.session_state.adapter_cache[idx]\n",
        "    model = PeftModel.from_pretrained(base_model, str(folder)).eval()\n",
        "    st.session_state.adapter_cache[idx] = {\"model\": model, \"tokenizer\": tokenizer}\n",
        "    return st.session_state.adapter_cache[idx]\n",
        "\n",
        "def extract_assistant_reply(text):\n",
        "    text = re.sub(r\"Cutting Knowledge.*?\\\\n\", \"\", text, flags=re.DOTALL)\n",
        "    text = re.sub(r\"<\\\\|.*?\\\\|>\", \"\", text)\n",
        "    # Use find instead of split to handle multiple \"assistant\" tokens\n",
        "    lower_text = text.lower()\n",
        "    for token in [\"assistant\\\\n\", \"assistant:\", \"assistant\"]:\n",
        "        if token in lower_text:\n",
        "            pos = lower_text.find(token)\n",
        "            text = text[pos + len(token):]\n",
        "            break\n",
        "    return text.strip()\n",
        "\n",
        "def format_prompt(sys, user):\n",
        "    try:\n",
        "        return tokenizer.apply_chat_template(\n",
        "            [{\"role\":\"system\",\"content\":sys},{\"role\":\"user\",\"content\":user}],\n",
        "            tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "    except:\n",
        "        return sys + \"\\\\n\\\\n\" + user\n",
        "\n",
        "# ----- NEW UI (from Advancements.pdf) -----\n",
        "\n",
        "# ----- NEW: Sidebar -----\n",
        "with st.sidebar:\n",
        "    st.markdown('<div class=\"sidebar-title\">Council Members</div>', unsafe_allow_html=True)\n",
        "    for i in range(1, 19):\n",
        "        name = LLM_LONG[i].split(\"-\")[0].strip()\n",
        "        st.markdown(f'<div class=\"member\">{i}. {name}</div>', unsafe_allow_html=True)\n",
        "\n",
        "# ----- NEW: Main Header -----\n",
        "header()\n",
        "\n",
        "# ----- NEW: Tabs -----\n",
        "tab_ask, tab_profiles = st.tabs([\"‚ú® Ask Council\", \"üìñ Council Profiles\"])\n",
        "\n",
        "# --- \"Ask Council\" Tab ---\n",
        "with tab_ask:\n",
        "    st.markdown('<div class=\"fade-in textarea\">', unsafe_allow_html=True)\n",
        "    query = st.text_area(\n",
        "        \"Your Question\",\n",
        "        key=\"user_input\",\n",
        "        placeholder=\"Describe your situation or question...\",\n",
        "        label_visibility=\"collapsed\"\n",
        "    )\n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    # NEW: Button row\n",
        "    btn_cols = st.columns([0.18, 0.18, 0.18, 0.46])\n",
        "    with btn_cols[0]:\n",
        "        generate_btn = st.button(\"Generate\", type=\"primary\")\n",
        "    with btn_cols[1]:\n",
        "        copy_btn = st.button(\"Copy\")\n",
        "    with btn_cols[2]:\n",
        "        clear_btn = st.button(\"Clear\")\n",
        "\n",
        "    if clear_btn:\n",
        "        st.session_state.pop(\"last_answer\", None)\n",
        "        st.session_state.pop(\"last_pred\", None)\n",
        "        st.rerun()\n",
        "\n",
        "    if copy_btn and st.session_state.get(\"last_answer\"):\n",
        "        st.code(st.session_state[\"last_answer\"], language=\"\")\n",
        "        st.success(\"Answer ready to copy\")\n",
        "\n",
        "    # NEW: Custom Loader\n",
        "    def council_loader():\n",
        "        st.markdown(\n",
        "            '''<div class=\"loader-wrap\">\n",
        "            <div class=\"loader-line\"><b>Council convening</b><span class=\"loader-dots\"></span></div>\n",
        "            <div class=\"loader-line\">Weighing perspectives<span class=\"loader-dots\"></span></div>\n",
        "            <div class=\"loader-line\">Illuminating the path<span class=\"loader-dots\"></span></div>\n",
        "            </div>''',\n",
        "            unsafe_allow_html=True\n",
        "        )\n",
        "\n",
        "    # Generation logic (modified to use session state)\n",
        "    if generate_btn:\n",
        "        if not query.strip():\n",
        "            st.warning(\"Please enter a question.\")\n",
        "        else:\n",
        "            # Show custom loader\n",
        "            loader_placeholder = st.empty()\n",
        "            loader_placeholder.markdown(council_loader(), unsafe_allow_html=True)\n",
        "\n",
        "            # --- Core Logic (Unchanged) ---\n",
        "            pred = int(router.predict([clean_text(query)])[0])\n",
        "            chapter = adapter_index_map.get(str(pred), {}).get(\"title\", f\"Chapter {pred}\")\n",
        "            folder = find_adapter(pred)\n",
        "\n",
        "            if not folder:\n",
        "                st.error(\"Selected expert unavailable.\")\n",
        "            else:\n",
        "                info = load_adapter(pred, folder)\n",
        "                sys = SYSTEM_PROMPTS.get(pred, \"\")\n",
        "                prompt = format_prompt(sys, query)\n",
        "\n",
        "                m = info[\"model\"]; t = info[\"tokenizer\"]\n",
        "                tokens = {k:v.to(DEVICE) for k,v in t(prompt, return_tensors=\"pt\").items()}\n",
        "                out = m.generate(**tokens, max_new_tokens=MAX_NEW_TOKENS)\n",
        "                raw = t.decode(out[0], skip_special_tokens=True)\n",
        "                text = extract_assistant_reply(raw)\n",
        "\n",
        "                # --- End Core Logic ---\n",
        "\n",
        "                # NEW: Save to session state\n",
        "                st.session_state[\"last_answer\"] = text\n",
        "                st.session_state[\"last_pred\"] = pred\n",
        "\n",
        "            # Clear loader\n",
        "            loader_placeholder.empty()\n",
        "            st.rerun() # Rerun to display the new answer from session state\n",
        "\n",
        "    # NEW: Display answer from session state\n",
        "    if st.session_state.get(\"last_answer\"):\n",
        "        pred_idx = st.session_state.get(\"last_pred\", \"??\")\n",
        "        guided = adapter_index_map.get(str(pred_idx), {}).get(\"title\", f\"Chapter {pred_idx}\")\n",
        "\n",
        "        st.markdown(f\"<div class='subtle' style='margin-top: 15px;'>Guided by: <b>{guided}</b></div>\", unsafe_allow_html=True)\n",
        "        st.markdown(f\"<div class='response fade-in'>{st.session_state['last_answer']}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown('<div class=\"divider\" style=\"margin-top: 20px;\"></div>', unsafe_allow_html=True)\n",
        "    st.markdown('<div style=\"color:var(--muted); text-align:center; font-size: 13.5px;\">\"Act well; release the fruit.\"</div>', unsafe_allow_html=True)\n",
        "\n",
        "# --- \"Council Profiles\" Tab ---\n",
        "with tab_profiles:\n",
        "    st.markdown(\"Explore the full roster of the Council. These are descriptive profiles (UI only) and do not affect routing.\", unsafe_allow_html=True)\n",
        "    st.markdown('<div class=\"divider\"></div>', unsafe_allow_html=True)\n",
        "\n",
        "    # NEW: 3-column responsive grid\n",
        "    cols = st.columns(3)\n",
        "    for i in range(1, 19):\n",
        "        col = cols[(i-1) % 3]\n",
        "        with col:\n",
        "            # Use a div with 100% height for consistent card sizing\n",
        "            st.markdown(f'''\n",
        "            <div class='card fade-in' style='height: 95%;'>\n",
        "                <b>{i}. {LLM_LONG[i].split(\"-\")[0].strip()}</b>\n",
        "                <div style='margin-top:6px; font-size:14px; color: var(--muted);'>\n",
        "                    {LLM_LONG[i].split(\"-\", 1)[-1].strip()}\n",
        "                </div>\n",
        "            </div>\n",
        "            ''', unsafe_allow_html=True)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Path(\"app.py\").write_text(app_code)\n",
        "print(\"‚úÖ app.py written successfully (Frontend customized to Advancements.pdf)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Uhulid2_9nf",
        "outputId": "33b6f70c-54df-4303-edf2-e26f4ec9fb14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ app.py written successfully (Frontend customized to Advancements.pdf)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: start streamlit and open an ngrok tunnel (if you want external access)\n",
        "import os\n",
        "from pyngrok import ngrok, conf\n",
        "import time\n",
        "NGROK_AUTH_TOKEN = \"35KiQqNVityZ8nDY043Tpt2WCOM_6fA3Y5VYRQYJtS4hREA7p\"  # <-- Paste your ngrok auth token here if you want a stable public URL\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    conf.get_default().auth_token = NGROK_AUTH_TOKEN\n",
        "\n",
        "# kill previous tunnels (if any)\n",
        "try:\n",
        "    ngrok.kill()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# start streamlit in background\n",
        "get_ipython().system_raw(\"streamlit run app.py --server.port 8501 --server.enableCORS false &\")\n",
        "\n",
        "# create a tunnel\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(\"Streamlit started. Public URL:\", public_url)\n",
        "print(\"If ngrok URL does not work, open http://127.0.0.1:8501 via Colab's port preview.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L9AQgyKgJ6zR",
        "outputId": "07b62b5c-a683-46ea-d504-dcd0018276e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit started. Public URL: NgrokTunnel: \"https://republishable-alonso-taxonomically.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "If ngrok URL does not work, open http://127.0.0.1:8501 via Colab's port preview.\n"
          ]
        }
      ]
    }
  ]
}